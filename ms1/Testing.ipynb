{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import glob\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "#Checks current directory for the midi file extension and returns a list of all the midi files\n",
    "def getMidi():\n",
    "    return glob.glob(\"Midi-Files/*.mid\")\n",
    "\n",
    "def chordTransform(chord): \n",
    "    #all possible triad chords\n",
    "    triads = {\n",
    "            'major' : [4, 3],\n",
    "            'minor' : [3, 4],\n",
    "            'dim' : [3, 3],\n",
    "            'aug' : [4, 4]\n",
    "        }\n",
    "    \n",
    "    #If not triad then returns a random note of the chord\n",
    "    if len(chord) != 3:\n",
    "        root_note = random.choice(chord)\n",
    "        return root_note\n",
    "    \n",
    "    #Finds the corresponding notes and its root note\n",
    "    root_chord = {}\n",
    "    for note in chord:\n",
    "        root_chord[note]= note%12\n",
    "    \n",
    "    # Get all possible permutations of these notes\n",
    "    note_perms = list(itertools.permutations(list(root_chord.values())))\n",
    "\n",
    "    # Test each permutation against the possible triad intervals and return the triad type if there's a match.\n",
    "    for i in range(len(note_perms)-1):\n",
    "        notes_intervals = []\n",
    "        posRoot_note = 99\n",
    "        root_note = 99\n",
    "\n",
    "        # Loop through notes and create a list, length 2, of intervals to check against\n",
    "        for j in range(len(chord)-1):\n",
    "            \n",
    "            #Stores the current and next note in the possible permutations\n",
    "            note_A = note_perms[i][j]\n",
    "            note_B = note_perms[i][j+1]\n",
    "            \n",
    "            #finds the interval\n",
    "            interval = note_B - note_A\n",
    "            \n",
    "            #If the interval is negative then loops around just a different octave\n",
    "            if interval < 0:\n",
    "                interval = interval + 12\n",
    "                \n",
    "            #Store the interval\n",
    "            notes_intervals.append(interval)\n",
    "            \n",
    "            #The lowest note is the possible root note so checks for that and stores it\n",
    "            if note_A <= note_B:\n",
    "                if note_A < posRoot_note:\n",
    "                    posRoot_note = note_A\n",
    "            if note_B <= note_A: \n",
    "                if note_B < posRoot_note:\n",
    "                    posRoot_note = note_B\n",
    "                    \n",
    "        # Finally loop through the traids dict to see if we have a match for a triad\n",
    "        for t in triads.keys():\n",
    "            if triads[t] == notes_intervals:\n",
    "                \n",
    "                #If so the root note is the lowest note of the triad\n",
    "                #This method finds a key given a value\n",
    "                for real_root, pseudo_root in root_chord.items():\n",
    "                    if pseudo_root == posRoot_note:\n",
    "                        return real_root\n",
    "            \n",
    "    #If not then the root note is a random note from the collection of notes\n",
    "    if root_note not in range(12):\n",
    "        root_note = random.choice(list(root_chord.keys()))\n",
    "        return root_note\n",
    "\n",
    "#@inputs: note_array is a matrix that is 128xinstrument.get_piano_roll() long. The number of columns is dependent upon how\n",
    "            # sample will be split by time\n",
    "\n",
    "#@returns: a vector that contains the root note at each time sample\n",
    "def instrument_to_vector(note_array):\n",
    "    note_array_transpose = np.transpose(note_array)\n",
    "    note_vector = np.empty(note_array.shape[1])\n",
    "    note_vector.fill(-1)\n",
    "    for i in range(note_array_transpose.shape[0]): #The i here will be the column number of the transpose, which is the note\n",
    "                                                   #This loop should iterate through the number of columns in transpose\n",
    "        note_list=[]\n",
    "        for number in note_array_transpose[i]:\n",
    "            if number!=-1:\n",
    "                note_list.append(number) #add the number aka the note being played \n",
    "                                        # if there is no number there is no note played so that place is 0\n",
    "            if len(note_list)!=1:\n",
    "                note_vector[i]=-1\n",
    "            else:\n",
    "                note_vector[i]=note_list[0]\n",
    "    return note_vector\n",
    "\n",
    "def NoteMatrix(midi_data, samplesPerSec):\n",
    "    #Defines how many samples per second\n",
    "    fs = samplesPerSec\n",
    "\n",
    "    #Returns the total amount of samples gotten\n",
    "    y = np.arange(0, midi_data.get_end_time(), 1./fs).shape[0]\n",
    "\n",
    "    #Our desired matrix has the amount of samples for every possible instrument\n",
    "    #noteMatrix = np.zeros(shape=(128, y))\n",
    "    noteMatrix = np.empty(shape=(128,y))\n",
    "    noteMatrix.fill(-1)\n",
    "\n",
    "    #Iterates through all the instruments of the midi song\n",
    "    for instrument in midi_data.instruments:\n",
    "\n",
    "        #Creates an array of all the notes the instrument can possibly play over a time sample and its velocity\n",
    "        total_notes = np.asarray(instrument.get_piano_roll(fs=fs, times=np.arange(0, midi_data.get_end_time(), 1./fs)))\n",
    "        total_notes[total_notes == 0] = -1\n",
    "        \n",
    "        #Holder for the final array that converts chords into notes making all instruments monophonic\n",
    "        converted_notes = np.zeros(shape=total_notes.shape)\n",
    "\n",
    "        #Goes through each time sample to see if notes repeat, if so find the root node of this chord\n",
    "        i=0\n",
    "        \n",
    "        for column in total_notes.T:\n",
    "\n",
    "            #Notes repeat in a time slice\n",
    "            if count_nonNegOne(column) > 1:\n",
    "\n",
    "                #create a list containing the notes played\n",
    "                chord = np.where(column>=0)[0]\n",
    "                \n",
    "                if len(chord) > 0:\n",
    "                    #finds the root note of the chord\n",
    "                    root_note = chordTransform(chord)\n",
    "\n",
    "                    #removes all other notes other than the root\n",
    "                    for note in chord:\n",
    "                        if note != root_note:\n",
    "                            column[note] = -1\n",
    "\n",
    "                    #Classify the time slice by the root note itself not velocity\n",
    "                    column[root_note] = root_note\n",
    "\n",
    "                #Store in the converted notes\n",
    "            converted_notes[:, i] = column\n",
    "            i += 1\n",
    "\n",
    "        #As every time splice has only one note with the note defined, convert into vector\n",
    "        instrument_vector = instrument_to_vector(converted_notes)\n",
    "\n",
    "        #For that instrument store the vector of the notes played out of all\n",
    "        noteMatrix[instrument.program] = instrument_vector\n",
    "    return noteMatrix\n",
    "\n",
    "#Testing purposes\n",
    "def count_nonNegOne(array):\n",
    "    count = 0\n",
    "    for i in array:\n",
    "        if i != -1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#For the creation of the label array for the RNN\n",
    "def get_label_vector(label):\n",
    "    label_array = np.zeros((1,7))\n",
    "    label_dict = {'hh':0,\n",
    "                 'cl':1,\n",
    "                 'cn':2,\n",
    "                 'ro':3,\n",
    "                 'ed':4,\n",
    "                 'pp':5,\n",
    "                 'mt':6}\n",
    "    label_array[0][label_dict[label]] = 1\n",
    "    return label_array\n",
    "\n",
    "#def main():\n",
    "    #Makes a list of all the note matrices for all midis\n",
    "#    midi_note = []\n",
    "\n",
    "    #Makes a list of all the labels for each corresponding midi's note matrix\n",
    "#    midi_label = []\n",
    "\n",
    "    #Iterates through all midis\n",
    "#    for midi in getMidi():\n",
    "\n",
    "        #Opens midi as a pretty midi file\n",
    "#        midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "        #creates the note matrix\n",
    "#        noteMatrix = NoteMatrix(midi_data, 10)\n",
    "\n",
    "        #adds to list of matrices\n",
    "#        midi_note.append(noteMatrix)\n",
    "\n",
    "        #stores the label of the midi file which is the first two letters of each midi\n",
    "#        midi_label.append(midi[:2])\n",
    "        \n",
    "#if __name__== \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I861309\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#Makes a list of all the note matrices for all midis\n",
    "midi_note = []\n",
    "\n",
    "#Makes a list of all the labels for each corresponding midi's note matrix\n",
    "midi_label = []\n",
    "\n",
    "#number of samples per second\n",
    "fs = 20\n",
    "\n",
    "#Iterates through all midis\n",
    "for midi in getMidi():\n",
    "\n",
    "    #Opens midi as a pretty midi file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "    #creates the note matrix\n",
    "    noteMatrix = NoteMatrix(midi_data, fs)\n",
    "    \n",
    "    #only gets the slice from 30 seconds to 90 seconds\n",
    "    start = 30*fs\n",
    "    end = 90*fs\n",
    "    \n",
    "    #Stores sequence length for tensorflow\n",
    "    sequence_length = end-start\n",
    "    \n",
    "    #Stores the first minute\n",
    "    noteMatrix = noteMatrix[:, start:end].T\n",
    "    \n",
    "    #adds to list of matrices\n",
    "    midi_note.append(noteMatrix)\n",
    "\n",
    "    #stores the label of the midi file which is the first two letters of each midi\n",
    "    abbrev = midi.split(\"\\\\\")[1][:2]\n",
    "    midi_label.append(get_label_vector(abbrev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "training_steps = 500\n",
    "batch_size = 1\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 128 #instruments\n",
    "timesteps = 60*fs # timesteps\n",
    "num_hidden = 4 # hidden layer num of features\n",
    "num_classes = 7 #Total amount of genres\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 1.7463, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 0.5903, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1.9071, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 0.5889, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 2.0698, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.7409, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.2268, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.6172, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 0.6885, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1.6740, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.8930, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 0.3213, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1.2627, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.2518, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.2075, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.7359, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.5852, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 1.7099, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.5839, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 2.0592, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.7308, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.1272, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.4318, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.6805, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 1.5233, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.6962, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.3176, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 1.2541, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.0927, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 2.1966, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.7248, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 0.5795, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 1.4989, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 0.5783, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 2.0479, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.7200, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.0865, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.2335, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 0.6713, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 1.3031, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.4855, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 0.3135, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 1.2449, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.0506, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 2.1848, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.7141, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.5739, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.2956, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.5727, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 2.0369, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.7095, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.0677, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.0458, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.6619, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.2586, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.2832, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.3095, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.2359, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.0292, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 2.1736, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.7036, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 0.5683, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.1154, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 0.5671, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 2.0263, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.6993, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.0548, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 0.8908, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 0.6521, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.2387, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.1052, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 0.3055, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.2272, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.0119, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 2.1629, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.6934, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 0.5627, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.9697, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.5615, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 2.0158, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.6893, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.0444, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 0.7741, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.6417, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 1.2248, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 0.9618, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.3015, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 1.2187, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.9959, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 2.1527, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.6833, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 0.5571, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.8531, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.5560, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 2.0056, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.6794, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.0351, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 0.6846, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.6304, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.2134, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.8468, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.2976, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.2104, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.9799, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 2.1427, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.6735, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 0.5517, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.7568, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.5505, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.9955, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.6697, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.0267, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 0.6121, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.6177, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.2032, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.7516, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.2938, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.2023, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.9627, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 2.1327, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.6638, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.5463, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.6757, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.5452, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.9857, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.6602, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.0187, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.5512, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.6029, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.1937, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.6714, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.2901, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.1944, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.9429, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 2.1225, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.6542, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 0.5410, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.6076, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.5399, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.9760, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.6508, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.0112, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90, Minibatch Loss= 0.4999, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.5848, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.1847, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.6041, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.2865, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.1867, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.9187, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 2.1101, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.6448, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 0.5358, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.5513, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.5347, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.9665, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.6416, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.0039, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 0.4579, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.5614, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.1760, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.5486, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.2829, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.1791, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.8865, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 2.0720, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.6356, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 0.5307, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.5053, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.5296, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.9571, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.6325, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 0.9970, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.4246, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.5305, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.1674, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.5032, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.2794, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.1716, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.8397, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.8354, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 1.6266, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 0.5256, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.4682, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.5245, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.9479, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 1.6236, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 0.9902, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.3993, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.4931, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.1589, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.4666, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.2760, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.1643, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.7681, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.6997, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 1.6178, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 0.5207, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.4381, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.5195, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.9388, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 1.6149, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 0.9837, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.3801, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.4580, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.1502, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.4369, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.2727, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.1572, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.6647, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.4345, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 1.6092, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 0.5157, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.4138, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.5145, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.9300, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 1.6064, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 0.9775, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.3654, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.4332, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.1411, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.4129, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.2694, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.1503, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.5495, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.0118, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.6009, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 0.5107, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.3948, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.5096, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.9212, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 1.5982, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 0.9714, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.3543, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.4174, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.1313, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.3940, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.2662, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.1437, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.4590, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.9342, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.5928, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 0.5059, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.3797, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.5048, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.9126, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 1.5901, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 0.9655, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.3455, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.4066, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.1196, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.3791, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.2631, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.1371, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.3999, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.9070, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.5847, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 0.5011, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3676, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.5000, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.9040, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 1.5822, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 0.9597, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3382, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3984, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.1027, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3670, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.2600, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.1307, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3619, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.8913, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.5768, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 0.4964, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.3575, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.4953, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.8956, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 1.5743, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 0.9540, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.3319, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.3917, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.0671, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.3569, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 180, Minibatch Loss= 0.2570, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.1243, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.3362, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.8800, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.5690, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.4918, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3489, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.4907, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.8872, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 1.5666, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.9484, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3263, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3858, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.9243, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3485, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.2541, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.1180, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3179, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.8708, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.5613, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 0.4872, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.3415, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.4861, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.8790, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 1.5590, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 0.9430, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.3212, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.3805, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.7032, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.3411, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.2512, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.1119, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.3041, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.8629, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.5538, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 0.4826, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.3347, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.4815, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.8709, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 1.5515, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 0.9376, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.3164, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.3755, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.6419, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.3342, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.2484, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.1059, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.2929, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.8560, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.5464, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 0.4781, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.3284, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.4770, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.8629, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 1.5442, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 0.9323, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.3118, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.3708, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.6167, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.3279, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.2456, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.1000, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.2836, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.8496, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.5390, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 0.4737, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.3225, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.4726, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.8549, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 1.5368, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 0.9271, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.3074, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.3663, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.6016, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.3221, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.2429, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.0941, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.2758, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.8435, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.5317, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 0.4693, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.3171, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.4683, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.8470, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 1.5296, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 0.9220, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.3032, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.3620, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.5905, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.3166, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.2402, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.0883, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.2689, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.8378, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.5244, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 0.4650, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.3120, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.4640, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.8392, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 1.5224, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 0.9169, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.2991, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.3579, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.5815, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.3115, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.2375, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.0825, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.2629, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.8323, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.5172, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 0.4608, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.3071, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.4598, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.8314, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 1.5153, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 0.9118, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.2952, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.3539, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.5736, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.3067, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.2349, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.0768, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.2574, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.8269, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.5101, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 0.4566, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.3025, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.4556, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.8236, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 1.5082, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 0.9068, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.2914, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.3500, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.5665, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.3021, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.2324, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.0711, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.2525, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.8217, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 280, Minibatch Loss= 1.5030, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 0.4524, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.2981, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.4515, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 1.8159, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 1.5012, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 0.9019, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.2877, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.3463, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.5598, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.2977, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.2299, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 1.0655, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.2480, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.8166, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.4960, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 0.4483, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.2939, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.4474, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.8082, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 1.4942, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 0.8970, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.2841, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.3427, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.5534, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.2935, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.2274, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.0600, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.2438, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.8116, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.4890, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 0.4443, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.2898, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.4434, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.8006, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 1.4873, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 0.8921, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.2806, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.3391, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.5472, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.2894, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.2250, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.0544, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.2398, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.8067, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.4821, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 0.4403, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2859, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.4394, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.7930, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 1.4804, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 0.8873, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2772, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.3357, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.5410, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2855, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2226, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.0490, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2361, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.8018, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.4752, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 0.4364, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2821, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.4355, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.7854, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 1.4736, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 0.8826, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2739, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.3323, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.5347, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2818, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2202, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.0436, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2326, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.7971, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.4684, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 0.4325, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2785, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.4316, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.7779, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 1.4668, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 0.8778, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2707, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.3290, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.5279, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2781, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2179, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.0382, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2293, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.7924, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.4617, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 0.4287, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.2749, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.4278, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.7704, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 1.4600, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 0.8732, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.2675, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.3257, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.5202, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.2746, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.2156, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.0329, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.2261, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.7878, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.4549, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 0.4249, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.2715, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.4241, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.7629, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 1.4534, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 0.8685, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.2644, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.3226, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.5103, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.2712, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.2134, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.0276, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.2231, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.7833, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.4483, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 0.4212, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2682, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.4203, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.7554, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 1.4467, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 0.8639, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2614, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.3195, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.4953, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2678, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2112, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.0223, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2202, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.7788, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.4417, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.4175, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.2650, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 370, Minibatch Loss= 0.4167, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.7479, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 1.4401, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.8594, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.2584, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.3164, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.4722, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.2646, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.2090, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.0171, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.2174, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.7743, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.4351, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 0.4139, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2618, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.4131, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.7404, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 1.4336, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 0.8549, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2555, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.3134, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.4504, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2615, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2068, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.0120, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2147, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.7699, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.4286, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 0.4103, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.2587, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.4095, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.7328, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 1.4271, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 0.8505, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.2527, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.3105, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.4377, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.2584, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.2047, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.0069, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.2120, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.7656, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 1.4221, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 0.4067, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2557, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.4060, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 1.7252, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 1.4207, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 0.8461, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2499, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.3076, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.4299, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2554, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2027, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 1.0018, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2095, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.7614, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 1.4157, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 0.4032, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2527, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.4025, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 1.7173, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 1.4143, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 0.8417, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2471, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.3048, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.4240, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2524, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2006, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.9968, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2070, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.7572, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 1.4094, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 0.3998, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.2498, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.3990, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 1.7091, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 1.4080, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 0.8374, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.2444, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.3020, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.4191, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.2495, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.1986, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.9919, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.2045, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.7530, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 1.4030, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 0.3964, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2469, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.3956, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 1.7001, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 1.4017, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 0.8331, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2418, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2993, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.4146, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2466, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.1966, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.9869, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2022, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.7489, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 1.3967, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 0.3930, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.2441, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.3923, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 1.6891, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 1.3954, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 0.8288, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.2392, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.2966, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.4105, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.2438, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.1947, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.9820, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.1999, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.7448, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 1.3905, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 0.3897, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.2414, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.3890, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 1.6702, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 1.3892, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 0.8246, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.2366, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.2940, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.4066, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.2411, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.1927, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.9772, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.1976, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.7408, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 1.3843, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 0.3864, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.2387, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.3857, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 1.4579, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 1.3831, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 0.8204, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.2341, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 460, Minibatch Loss= 0.2914, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.4028, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.2384, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.1908, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.9724, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.1954, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.7368, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 1.3785, Training Accuracy= 0.000\n",
      "Step 470, Minibatch Loss= 0.3833, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.2361, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.3826, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.7612, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 1.3773, Training Accuracy= 0.000\n",
      "Step 470, Minibatch Loss= 0.8164, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.2317, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.2889, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.3993, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.2358, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.1889, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.9678, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.1932, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.7325, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 1.3727, Training Accuracy= 0.000\n",
      "Step 480, Minibatch Loss= 0.3802, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.2336, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.3795, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.7511, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 1.3716, Training Accuracy= 0.000\n",
      "Step 480, Minibatch Loss= 0.8125, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.2293, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.2864, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.3958, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.2333, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.1869, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.9634, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.1910, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.7281, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 1.3671, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 0.3772, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.2312, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.3765, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.7447, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 1.3659, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 0.8086, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.2270, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.2840, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.3925, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.2309, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.1849, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.9590, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.1888, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.7238, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 1.3614, Training Accuracy= 0.000\n",
      "Step 500, Minibatch Loss= 0.3742, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.2287, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.3735, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.7394, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 1.3603, Training Accuracy= 0.000\n",
      "Step 500, Minibatch Loss= 0.8047, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.2247, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.2816, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.3892, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.2285, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.1830, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.9546, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.1867, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.7195, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.0\n",
      "Testing Accuracy: 0.0\n",
      "Testing Accuracy: 1.0\n",
      "Testing Accuracy: 1.0\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        for i in range(len(midi_note)-5):\n",
    "            batch_x = midi_note[i]\n",
    "            batch_y = midi_label[i]\n",
    "            # Reshape data to get 60*fs seq of 128 elements\n",
    "            batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for test\n",
    "    for i in range(5):\n",
    "        i = i+15\n",
    "        test_data = midi_note[i]\n",
    "        test_label = midi_label[i]\n",
    "        # Reshape data to get 60*fs seq of 128 elements\n",
    "        test_data = test_data.reshape((batch_size, timesteps, num_input))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
