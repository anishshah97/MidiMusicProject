{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import glob\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "#Checks current directory for the midi file extension and returns a list of all the midi files\n",
    "def getMidi():\n",
    "    return glob.glob(\"Midi-Files/*.mid\")\n",
    "\n",
    "def chordTransform(chord): \n",
    "    #all possible triad chords\n",
    "    triads = {\n",
    "            'major' : [4, 3],\n",
    "            'minor' : [3, 4],\n",
    "            'dim' : [3, 3],\n",
    "            'aug' : [4, 4]\n",
    "        }\n",
    "    \n",
    "    #If not triad then returns a random note of the chord\n",
    "    if len(chord) != 3:\n",
    "        root_note = random.choice(chord)\n",
    "        return root_note\n",
    "    \n",
    "    #Finds the corresponding notes and its root note\n",
    "    root_chord = {}\n",
    "    for note in chord:\n",
    "        root_chord[note]= note%12\n",
    "    \n",
    "    # Get all possible permutations of these notes\n",
    "    note_perms = list(itertools.permutations(list(root_chord.values())))\n",
    "\n",
    "    # Test each permutation against the possible triad intervals and return the triad type if there's a match.\n",
    "    for i in range(len(note_perms)-1):\n",
    "        notes_intervals = []\n",
    "        posRoot_note = 99\n",
    "        root_note = 99\n",
    "\n",
    "        # Loop through notes and create a list, length 2, of intervals to check against\n",
    "        for j in range(len(chord)-1):\n",
    "            \n",
    "            #Stores the current and next note in the possible permutations\n",
    "            note_A = note_perms[i][j]\n",
    "            note_B = note_perms[i][j+1]\n",
    "            \n",
    "            #finds the interval\n",
    "            interval = note_B - note_A\n",
    "            \n",
    "            #If the interval is negative then loops around just a different octave\n",
    "            if interval < 0:\n",
    "                interval = interval + 12\n",
    "                \n",
    "            #Store the interval\n",
    "            notes_intervals.append(interval)\n",
    "            \n",
    "            #The lowest note is the possible root note so checks for that and stores it\n",
    "            if note_A <= note_B:\n",
    "                if note_A < posRoot_note:\n",
    "                    posRoot_note = note_A\n",
    "            if note_B <= note_A: \n",
    "                if note_B < posRoot_note:\n",
    "                    posRoot_note = note_B\n",
    "                    \n",
    "        # Finally loop through the traids dict to see if we have a match for a triad\n",
    "        for t in triads.keys():\n",
    "            if triads[t] == notes_intervals:\n",
    "                \n",
    "                #If so the root note is the lowest note of the triad\n",
    "                #This method finds a key given a value\n",
    "                for real_root, pseudo_root in root_chord.items():\n",
    "                    if pseudo_root == posRoot_note:\n",
    "                        return real_root\n",
    "            \n",
    "    #If not then the root note is a random note from the collection of notes\n",
    "    if root_note not in range(12):\n",
    "        root_note = random.choice(list(root_chord.keys()))\n",
    "        return root_note\n",
    "\n",
    "#@inputs: note_array is a matrix that is 128xinstrument.get_piano_roll() long. The number of columns is dependent upon how\n",
    "            # sample will be split by time\n",
    "\n",
    "#@returns: a vector that contains the root note at each time sample\n",
    "def instrument_to_vector(note_array):\n",
    "    note_array_transpose = np.transpose(note_array)\n",
    "    note_vector = np.empty(note_array.shape[1])\n",
    "    note_vector.fill(-1)\n",
    "    for i in range(note_array_transpose.shape[0]): #The i here will be the column number of the transpose, which is the note\n",
    "                                                   #This loop should iterate through the number of columns in transpose\n",
    "        note_list=[]\n",
    "        for number in note_array_transpose[i]:\n",
    "            if number!=-1:\n",
    "                note_list.append(number) #add the number aka the note being played \n",
    "                                        # if there is no number there is no note played so that place is 0\n",
    "            if len(note_list)!=1:\n",
    "                note_vector[i]=-1\n",
    "            else:\n",
    "                note_vector[i]=note_list[0]\n",
    "    return note_vector\n",
    "\n",
    "def NoteMatrix(midi_data, samplesPerSec):\n",
    "    #Defines how many samples per second\n",
    "    fs = samplesPerSec\n",
    "\n",
    "    #Returns the total amount of samples gotten\n",
    "    y = np.arange(0, midi_data.get_end_time(), 1./fs).shape[0]\n",
    "\n",
    "    #Our desired matrix has the amount of samples for every possible instrument\n",
    "    #noteMatrix = np.zeros(shape=(128, y))\n",
    "    noteMatrix = np.empty(shape=(128,y))\n",
    "    noteMatrix.fill(-1)\n",
    "\n",
    "    #Iterates through all the instruments of the midi song\n",
    "    for instrument in midi_data.instruments:\n",
    "\n",
    "        #Creates an array of all the notes the instrument can possibly play over a time sample and its velocity\n",
    "        total_notes = np.asarray(instrument.get_piano_roll(fs=fs, times=np.arange(0, midi_data.get_end_time(), 1./fs)))\n",
    "        total_notes[total_notes == 0] = -1\n",
    "        \n",
    "        #Holder for the final array that converts chords into notes making all instruments monophonic\n",
    "        converted_notes = np.zeros(shape=total_notes.shape)\n",
    "\n",
    "        #Goes through each time sample to see if notes repeat, if so find the root node of this chord\n",
    "        i=0\n",
    "        \n",
    "        for column in total_notes.T:\n",
    "\n",
    "            #Notes repeat in a time slice\n",
    "            if count_nonNegOne(column) > 1:\n",
    "\n",
    "                #create a list containing the notes played\n",
    "                chord = np.where(column>=0)[0]\n",
    "                \n",
    "                if len(chord) > 0:\n",
    "                    #finds the root note of the chord\n",
    "                    root_note = chordTransform(chord)\n",
    "\n",
    "                    #removes all other notes other than the root\n",
    "                    for note in chord:\n",
    "                        if note != root_note:\n",
    "                            column[note] = -1\n",
    "\n",
    "                    #Classify the time slice by the root note itself not velocity\n",
    "                    column[root_note] = root_note\n",
    "\n",
    "                #Store in the converted notes\n",
    "            converted_notes[:, i] = column\n",
    "            i += 1\n",
    "\n",
    "        #As every time splice has only one note with the note defined, convert into vector\n",
    "        instrument_vector = instrument_to_vector(converted_notes)\n",
    "\n",
    "        #For that instrument store the vector of the notes played out of all\n",
    "        noteMatrix[instrument.program] = instrument_vector\n",
    "    return noteMatrix\n",
    "\n",
    "#Testing purposes\n",
    "def count_nonNegOne(array):\n",
    "    count = 0\n",
    "    for i in array:\n",
    "        if i != -1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "#For the creation of the label array for the RNN\n",
    "def get_label_vector(label):\n",
    "    #Creates a (1,7) numpy array of zeroes\n",
    "    label_array = np.zeros((1,7))\n",
    "    label_dict = {'hh':0,\n",
    "                 'cl':1,\n",
    "                 'cn':2,\n",
    "                 'ro':3,\n",
    "                 'ed':4,\n",
    "                 'pp':5,\n",
    "                 'mt':6}\n",
    "    #Replaces the index position representing the genre with a 1\n",
    "    label_array[0][label_dict[label]] = 1\n",
    "    return label_array\n",
    "\n",
    "#def main():\n",
    "    #Makes a list of all the note matrices for all midis\n",
    "#    midi_note = []\n",
    "\n",
    "    #Makes a list of all the labels for each corresponding midi's note matrix\n",
    "#    midi_label = []\n",
    "\n",
    "    #Iterates through all midis\n",
    "#    for midi in getMidi():\n",
    "\n",
    "        #Opens midi as a pretty midi file\n",
    "#        midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "        #creates the note matrix\n",
    "#        noteMatrix = NoteMatrix(midi_data, 10)\n",
    "\n",
    "        #adds to list of matrices\n",
    "#        midi_note.append(noteMatrix)\n",
    "\n",
    "        #stores the label of the midi file which is the first two letters of each midi\n",
    "#        midi_label.append(midi[:2])\n",
    "        \n",
    "#if __name__== \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I861309\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#Makes a list of all the note matrices for all midis\n",
    "midi_note = []\n",
    "\n",
    "#Makes a list of all the labels for each corresponding midi's note matrix\n",
    "midi_label = []\n",
    "\n",
    "#number of samples per second\n",
    "fs = 20\n",
    "\n",
    "#Iterates through all midis\n",
    "for midi in getMidi():\n",
    "\n",
    "    #Opens midi as a pretty midi file\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi)\n",
    "\n",
    "    #creates the note matrix\n",
    "    noteMatrix = NoteMatrix(midi_data, fs)\n",
    "    \n",
    "    #only gets the slice from 30 seconds to 90 seconds\n",
    "    start = 30*fs\n",
    "    end = 90*fs\n",
    "    \n",
    "    #Stores sequence length for tensorflow\n",
    "    sequence_length = end-start\n",
    "    \n",
    "    #Stores the first minute\n",
    "    noteMatrix = noteMatrix[:, start:end].T\n",
    "    \n",
    "    #adds to list of matrices\n",
    "    midi_note.append(noteMatrix)\n",
    "\n",
    "    #stores the label of the midi file which is the first two letters of each midi\n",
    "    abbrev = midi.split(\"\\\\\")[1][:2]\n",
    "    midi_label.append(get_label_vector(abbrev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "training_steps = 600\n",
    "batch_size = 1\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 128 #instruments\n",
    "timesteps = 60*fs # timesteps\n",
    "num_hidden = 4 # hidden layer num of features\n",
    "num_classes = 7 #Total amount of genres\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    #Dropout\n",
    "    lstm_cell = rnn.DropoutWrapper(lstm_cell, output_keep_prob=0.9)\n",
    "    \n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2.1152, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.6431, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.6820, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.6739, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 4.0019, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 0.8895, Training Accuracy= 1.000\n",
      "Step 1, Minibatch Loss= 1.8433, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.2189, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.7155, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 3.8122, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.5410, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 1.9547, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 3.5128, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 2.7210, Training Accuracy= 0.000\n",
      "Step 1, Minibatch Loss= 3.0918, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 0.8820, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 1.5394, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.9147, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 2.0406, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 3.5315, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 2.1003, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.5014, Training Accuracy= 1.000\n",
      "Step 10, Minibatch Loss= 1.9757, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 2.4235, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 3.4338, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.8747, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 1.4414, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 3.1231, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 2.6206, Training Accuracy= 0.000\n",
      "Step 10, Minibatch Loss= 3.5361, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 0.8725, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 1.4840, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.6707, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.7370, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.0331, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 0.8724, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 0.9760, Training Accuracy= 1.000\n",
      "Step 20, Minibatch Loss= 1.4192, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 2.1381, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 2.6878, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.3611, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 1.9173, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 2.0519, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 2.5559, Training Accuracy= 0.000\n",
      "Step 20, Minibatch Loss= 3.0521, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.8631, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.4518, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.1774, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.2356, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 0.7323, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 2.0732, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 0.8917, Training Accuracy= 1.000\n",
      "Step 30, Minibatch Loss= 1.5131, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.6514, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 2.4856, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.5714, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.9006, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 1.8791, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 2.4722, Training Accuracy= 0.000\n",
      "Step 30, Minibatch Loss= 3.0345, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 0.8545, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.4269, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.1028, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.2148, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 0.6167, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 0.8542, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 0.8554, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.1283, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.5199, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 2.3133, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.0989, Training Accuracy= 1.000\n",
      "Step 40, Minibatch Loss= 1.8849, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.8065, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 1.4051, Training Accuracy= 0.000\n",
      "Step 40, Minibatch Loss= 3.0179, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 0.8451, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 2.0498, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.0553, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 1.1950, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.5558, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.8453, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 0.8294, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 1.0768, Training Accuracy= 1.000\n",
      "Step 50, Minibatch Loss= 1.4566, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.7777, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.4229, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 2.6213, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 1.7640, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 2.0630, Training Accuracy= 0.000\n",
      "Step 50, Minibatch Loss= 3.0017, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 0.8363, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.3856, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.0202, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.1755, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.5194, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 0.8366, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.6981, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.3336, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.4215, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 2.0575, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.0178, Training Accuracy= 1.000\n",
      "Step 60, Minibatch Loss= 1.8555, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.7321, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 1.7313, Training Accuracy= 0.000\n",
      "Step 60, Minibatch Loss= 2.9849, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 2.0242, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.3678, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 0.9864, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.1565, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.4946, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.8281, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 0.7801, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.0018, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.3954, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.6437, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 0.9220, Training Accuracy= 1.000\n",
      "Step 70, Minibatch Loss= 1.8414, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.7088, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 1.5664, Training Accuracy= 0.000\n",
      "Step 70, Minibatch Loss= 2.9692, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.8194, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.3517, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.9564, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.1368, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 0.6259, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 2.0137, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.7777, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.4271, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.3502, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.6240, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 0.9545, Training Accuracy= 1.000\n",
      "Step 80, Minibatch Loss= 1.8281, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 2.0131, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.4669, Training Accuracy= 0.000\n",
      "Step 80, Minibatch Loss= 1.6442, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 0.8111, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.3355, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 0.9281, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.1177, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.6367, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.8115, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 0.7630, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90, Minibatch Loss= 0.9394, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.3541, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.6066, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 0.9264, Training Accuracy= 1.000\n",
      "Step 90, Minibatch Loss= 1.8148, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.6689, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 1.4154, Training Accuracy= 0.000\n",
      "Step 90, Minibatch Loss= 2.9380, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 0.8036, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.3200, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.9013, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.1008, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 0.4478, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.9913, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 0.9944, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.2999, Training Accuracy= 1.000\n",
      "Step 100, Minibatch Loss= 1.3361, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.5901, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.3928, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.8018, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.6519, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.3821, Training Accuracy= 0.000\n",
      "Step 100, Minibatch Loss= 1.6178, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 0.7949, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.3049, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.4565, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.0850, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.4355, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.7952, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.7363, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 0.8347, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.3186, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.5709, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.1498, Training Accuracy= 1.000\n",
      "Step 110, Minibatch Loss= 1.7883, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.6366, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 1.3553, Training Accuracy= 0.000\n",
      "Step 110, Minibatch Loss= 2.9076, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 0.7869, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.2902, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.8521, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.0699, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.4248, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.7873, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.7179, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 0.8600, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.3016, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.5604, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 0.8506, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.7750, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 1.6213, Training Accuracy= 0.000\n",
      "Step 120, Minibatch Loss= 1.2869, Training Accuracy= 1.000\n",
      "Step 120, Minibatch Loss= 1.5924, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 0.7798, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.2754, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.8296, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.3952, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 0.4161, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.7795, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 0.7124, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.3070, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.2862, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.5460, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 0.8284, Training Accuracy= 1.000\n",
      "Step 130, Minibatch Loss= 1.7615, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 1.6068, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 1.3135, Training Accuracy= 0.000\n",
      "Step 130, Minibatch Loss= 2.8774, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 0.7721, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.2613, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.0890, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.0410, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.4074, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.7718, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.7018, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 0.8146, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.2711, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.5317, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 0.8066, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 1.7485, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 1.5919, Training Accuracy= 0.000\n",
      "Step 140, Minibatch Loss= 1.2945, Training Accuracy= 1.000\n",
      "Step 140, Minibatch Loss= 2.8624, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 0.7637, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.2473, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.7867, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.3692, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 0.3987, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.7642, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.6915, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 0.7497, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.2560, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.5180, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 0.7854, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 1.7355, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 1.5781, Training Accuracy= 0.000\n",
      "Step 150, Minibatch Loss= 1.2776, Training Accuracy= 1.000\n",
      "Step 150, Minibatch Loss= 2.8478, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 0.7563, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.2336, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.7221, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.0132, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.3907, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.7567, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 0.9390, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.6870, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 1.2409, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.5047, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 0.7656, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 1.7226, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 1.9250, Training Accuracy= 0.000\n",
      "Step 160, Minibatch Loss= 1.2601, Training Accuracy= 1.000\n",
      "Step 160, Minibatch Loss= 2.8328, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 0.7488, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.2202, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.2353, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.9993, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.3830, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.7492, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.6721, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 0.7529, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.2266, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.4870, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 0.7463, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 1.7104, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 1.9144, Training Accuracy= 0.000\n",
      "Step 170, Minibatch Loss= 1.2454, Training Accuracy= 1.000\n",
      "Step 170, Minibatch Loss= 2.8175, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 1.9029, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 1.2069, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.7287, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.4656, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 0.4997, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.7420, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.6628, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 0.6952, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.2136, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 1.4774, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 0.7276, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 180, Minibatch Loss= 1.6982, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 1.5370, Training Accuracy= 0.000\n",
      "Step 180, Minibatch Loss= 1.2308, Training Accuracy= 1.000\n",
      "Step 180, Minibatch Loss= 2.8032, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.7344, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.1941, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.6260, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.9727, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.3687, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 0.7349, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.4600, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.7149, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.2002, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 1.4618, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 0.9986, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 2.5010, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 1.5240, Training Accuracy= 0.000\n",
      "Step 190, Minibatch Loss= 1.2164, Training Accuracy= 1.000\n",
      "Step 190, Minibatch Loss= 2.7889, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 0.7272, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.1802, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.6931, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.4402, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 0.3619, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.7277, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.6452, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 0.6975, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.1870, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 1.4516, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 0.9661, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 2.4929, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 1.5114, Training Accuracy= 0.000\n",
      "Step 200, Minibatch Loss= 1.2021, Training Accuracy= 1.000\n",
      "Step 200, Minibatch Loss= 2.7750, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 0.7202, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.1687, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.1547, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.9472, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.3553, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.7207, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.6366, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 0.6803, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.8834, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 1.4358, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 0.6751, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 1.6624, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 1.4986, Training Accuracy= 0.000\n",
      "Step 210, Minibatch Loss= 1.1867, Training Accuracy= 1.000\n",
      "Step 210, Minibatch Loss= 2.7607, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 1.8623, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 1.1561, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.6596, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.9346, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.3489, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.7138, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.8899, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 0.6636, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.1605, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.4263, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 0.6587, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 1.6504, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 1.8704, Training Accuracy= 0.000\n",
      "Step 220, Minibatch Loss= 1.1740, Training Accuracy= 1.000\n",
      "Step 220, Minibatch Loss= 2.7470, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 0.7064, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.1439, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.6439, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.9222, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.4592, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.7069, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.8822, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 0.6476, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.1485, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.4139, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 0.6429, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.6389, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 1.4741, Training Accuracy= 0.000\n",
      "Step 230, Minibatch Loss= 1.1606, Training Accuracy= 1.000\n",
      "Step 230, Minibatch Loss= 1.4590, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 0.6997, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.1317, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.6287, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.2596, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 0.3367, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.7002, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.6120, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 0.6323, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.1305, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.4019, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 0.6278, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.1248, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.4622, Training Accuracy= 0.000\n",
      "Step 240, Minibatch Loss= 1.1475, Training Accuracy= 1.000\n",
      "Step 240, Minibatch Loss= 1.4476, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 0.6929, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.1199, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.0798, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.8982, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.3309, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.6934, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.6040, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 0.9345, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.1239, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.3873, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 0.6133, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.1132, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 1.4502, Training Accuracy= 0.000\n",
      "Step 250, Minibatch Loss= 1.1347, Training Accuracy= 1.000\n",
      "Step 250, Minibatch Loss= 2.7053, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 0.6864, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.1078, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.5997, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.8863, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.3252, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.6869, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.5964, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.8594, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.1117, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.3780, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 0.5989, Training Accuracy= 1.000\n",
      "Step 260, Minibatch Loss= 1.6040, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 1.4337, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 1.8453, Training Accuracy= 0.000\n",
      "Step 260, Minibatch Loss= 2.6919, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 0.6799, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.8166, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 0.5860, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.8749, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.4309, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.6804, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.5889, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.5605, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.0998, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 1.3664, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 0.5852, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 2.4393, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 1.4273, Training Accuracy= 0.000\n",
      "Step 270, Minibatch Loss= 1.1093, Training Accuracy= 1.000\n",
      "Step 270, Minibatch Loss= 2.6783, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 280, Minibatch Loss= 0.6735, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 1.0846, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.5725, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.8633, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.3143, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.6741, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.5813, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.5477, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 1.8128, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 1.3547, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 0.5717, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 1.5813, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 1.4113, Training Accuracy= 0.000\n",
      "Step 280, Minibatch Loss= 1.0835, Training Accuracy= 1.000\n",
      "Step 280, Minibatch Loss= 3.1953, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 1.7944, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 1.0734, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.9571, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.8520, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.4819, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.7962, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 0.5722, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 0.5625, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.0766, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.8003, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 0.5589, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 1.5705, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 1.4044, Training Accuracy= 0.000\n",
      "Step 290, Minibatch Loss= 1.0856, Training Accuracy= 1.000\n",
      "Step 290, Minibatch Loss= 2.6512, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 0.6617, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.0624, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.5472, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.8408, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.3042, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.7867, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 0.8306, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.5501, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.0655, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.3314, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 0.5465, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.5599, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 1.7912, Training Accuracy= 0.000\n",
      "Step 300, Minibatch Loss= 1.0739, Training Accuracy= 1.000\n",
      "Step 300, Minibatch Loss= 1.3812, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 0.6548, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.0513, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.9270, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.8299, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.2991, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.6554, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.5578, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.5378, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.0538, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.3202, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 0.8041, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 1.5490, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 1.3820, Training Accuracy= 0.000\n",
      "Step 310, Minibatch Loss= 1.0624, Training Accuracy= 1.000\n",
      "Step 310, Minibatch Loss= 2.6241, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 0.6487, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.0394, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.8459, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 1.2993, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.2943, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.6493, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.5525, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.5260, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.0432, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.3092, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 0.5227, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.0349, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 1.3713, Training Accuracy= 0.000\n",
      "Step 320, Minibatch Loss= 1.0510, Training Accuracy= 1.000\n",
      "Step 320, Minibatch Loss= 2.6112, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 0.6428, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.0295, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.5119, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.8084, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.2896, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.6434, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.5456, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.5144, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.0322, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.2980, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 0.5113, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 1.5274, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 1.3604, Training Accuracy= 0.000\n",
      "Step 330, Minibatch Loss= 1.0397, Training Accuracy= 1.000\n",
      "Step 330, Minibatch Loss= 2.5980, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 0.6369, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.7515, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 0.5011, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.7979, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.3880, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.6375, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.5388, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.5034, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.0214, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 1.2872, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 0.5004, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 2.3890, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 1.3498, Training Accuracy= 0.000\n",
      "Step 340, Minibatch Loss= 1.0287, Training Accuracy= 1.000\n",
      "Step 340, Minibatch Loss= 2.5849, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 1.7389, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 1.0083, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.9175, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.7876, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.4509, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.6318, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.5322, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.4925, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.0103, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.2748, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 0.4896, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.5063, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 1.3393, Training Accuracy= 0.000\n",
      "Step 350, Minibatch Loss= 1.0178, Training Accuracy= 1.000\n",
      "Step 350, Minibatch Loss= 1.3291, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 0.6254, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.9978, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.7133, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.7772, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.2761, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.6260, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.5256, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.7329, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.0001, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.2656, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 0.4791, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 1.4958, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 1.3288, Training Accuracy= 0.000\n",
      "Step 360, Minibatch Loss= 1.0069, Training Accuracy= 1.000\n",
      "Step 360, Minibatch Loss= 2.5592, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.6197, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.9876, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.4697, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.7672, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 370, Minibatch Loss= 0.3716, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.7232, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.7836, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.7220, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 0.9864, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.7264, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.4692, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 1.4856, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 1.3185, Training Accuracy= 0.000\n",
      "Step 370, Minibatch Loss= 0.9965, Training Accuracy= 1.000\n",
      "Step 370, Minibatch Loss= 2.5465, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 0.6141, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.9777, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.4600, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.7575, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.2677, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.7145, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 0.5129, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.4620, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.9798, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.2448, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 0.7573, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 1.4757, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 1.7179, Training Accuracy= 0.000\n",
      "Step 380, Minibatch Loss= 0.9862, Training Accuracy= 1.000\n",
      "Step 380, Minibatch Loss= 2.5338, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 0.6087, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.9678, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.7127, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.7476, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.7059, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 0.6094, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.7697, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.7657, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.9697, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.2343, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 0.4499, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 1.4660, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 1.2982, Training Accuracy= 0.000\n",
      "Step 390, Minibatch Loss= 0.9761, Training Accuracy= 1.000\n",
      "Step 390, Minibatch Loss= 2.5210, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 0.6032, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.9580, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.4413, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.7381, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.2596, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.6039, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.5005, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.4432, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.9599, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 1.2243, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 0.4408, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 1.4559, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 1.2885, Training Accuracy= 0.000\n",
      "Step 400, Minibatch Loss= 0.9562, Training Accuracy= 1.000\n",
      "Step 400, Minibatch Loss= 2.5090, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 0.5979, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.9484, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.7290, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.7288, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.2557, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.5985, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.4944, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.8265, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 1.6936, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 1.2142, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.4319, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 1.4463, Training Accuracy= 0.000\n",
      "Step 410, Minibatch Loss= 1.2785, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 0.9553, Training Accuracy= 1.000\n",
      "Step 410, Minibatch Loss= 1.6882, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 0.5925, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.9386, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.4236, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.7195, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.2518, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.5932, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.4885, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.4254, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.9404, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 1.2042, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 0.4231, Training Accuracy= 1.000\n",
      "Step 420, Minibatch Loss= 1.4361, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 1.6832, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 1.6935, Training Accuracy= 0.000\n",
      "Step 420, Minibatch Loss= 2.4839, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 0.5873, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.9293, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.4153, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 1.0618, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.2481, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.5880, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.7465, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.4170, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.9309, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 1.1944, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.6720, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 1.4264, Training Accuracy= 0.000\n",
      "Step 430, Minibatch Loss= 1.2592, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 0.9364, Training Accuracy= 1.000\n",
      "Step 430, Minibatch Loss= 3.0382, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 0.5821, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.9199, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.7022, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.7015, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.2443, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.5828, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.4760, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.4088, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.9215, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 1.1849, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.4066, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 1.4166, Training Accuracy= 0.000\n",
      "Step 440, Minibatch Loss= 1.2499, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 0.9268, Training Accuracy= 1.000\n",
      "Step 440, Minibatch Loss= 2.4599, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 0.5770, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 1.6569, Training Accuracy= 0.000\n",
      "Step 450, Minibatch Loss= 0.3990, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.6927, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.4060, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.5777, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.4714, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.4006, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.9120, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 1.1754, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.3985, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.9064, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 1.2406, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 0.9087, Training Accuracy= 1.000\n",
      "Step 450, Minibatch Loss= 2.4481, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 1.6447, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 0.9012, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.3911, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.6837, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.2371, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.5727, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.7289, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.3926, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 460, Minibatch Loss= 1.6513, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 1.1657, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.3906, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 1.3972, Training Accuracy= 0.000\n",
      "Step 460, Minibatch Loss= 1.2311, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 0.9077, Training Accuracy= 1.000\n",
      "Step 460, Minibatch Loss= 1.2232, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.5670, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.8921, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.6353, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 1.1474, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.2336, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.5678, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.7222, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.7549, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.8935, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 1.1566, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.3832, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 1.3876, Training Accuracy= 0.000\n",
      "Step 470, Minibatch Loss= 1.2222, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 0.8985, Training Accuracy= 1.000\n",
      "Step 470, Minibatch Loss= 2.4246, Training Accuracy= 0.000\n",
      "Step 480, Minibatch Loss= 0.5622, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.8832, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.3762, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.6668, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.2301, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.5629, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.4551, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.3776, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.8843, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 1.1474, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.7498, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 1.3784, Training Accuracy= 0.000\n",
      "Step 480, Minibatch Loss= 1.2132, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 0.8894, Training Accuracy= 1.000\n",
      "Step 480, Minibatch Loss= 2.4135, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 0.5573, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 1.6246, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 0.3690, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.6585, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.2268, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.5581, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.4499, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.7328, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.8758, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 1.1382, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.3686, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 1.3691, Training Accuracy= 0.000\n",
      "Step 490, Minibatch Loss= 1.2042, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 0.8805, Training Accuracy= 1.000\n",
      "Step 490, Minibatch Loss= 2.4016, Training Accuracy= 0.000\n",
      "Step 500, Minibatch Loss= 0.5526, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.8660, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.3619, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.6503, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.2236, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.5534, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 1.1206, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.3633, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.8672, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 1.1291, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.3616, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 1.3601, Training Accuracy= 0.000\n",
      "Step 500, Minibatch Loss= 1.1953, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 0.8717, Training Accuracy= 1.000\n",
      "Step 500, Minibatch Loss= 2.9712, Training Accuracy= 0.000\n",
      "Step 510, Minibatch Loss= 0.5479, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.8574, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.6452, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.6423, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.2204, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.5486, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.7011, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.3565, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.8587, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 1.1202, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.6447, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 1.3512, Training Accuracy= 0.000\n",
      "Step 510, Minibatch Loss= 1.1866, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 0.8631, Training Accuracy= 1.000\n",
      "Step 510, Minibatch Loss= 2.3788, Training Accuracy= 0.000\n",
      "Step 520, Minibatch Loss= 0.5432, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.8491, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.3487, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 1.1024, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.2173, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.5440, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.4346, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.3500, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.8503, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 1.1113, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.3483, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.8455, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 1.1779, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 0.8546, Training Accuracy= 1.000\n",
      "Step 520, Minibatch Loss= 2.3675, Training Accuracy= 0.000\n",
      "Step 530, Minibatch Loss= 0.5386, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.8409, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.3422, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 1.0935, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.2988, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.5394, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.4295, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.6913, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.8417, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 1.1024, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 0.3418, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 1.3337, Training Accuracy= 0.000\n",
      "Step 530, Minibatch Loss= 1.5945, Training Accuracy= 0.000\n",
      "Step 530, Minibatch Loss= 0.8400, Training Accuracy= 1.000\n",
      "Step 530, Minibatch Loss= 2.9431, Training Accuracy= 0.000\n",
      "Step 540, Minibatch Loss= 0.5340, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.8327, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.3360, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.6189, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.2113, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.5348, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.4239, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.3371, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.8338, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 1.0936, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.5776, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 1.3251, Training Accuracy= 0.000\n",
      "Step 540, Minibatch Loss= 1.1606, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 0.8380, Training Accuracy= 1.000\n",
      "Step 540, Minibatch Loss= 2.3448, Training Accuracy= 0.000\n",
      "Step 550, Minibatch Loss= 0.5296, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 1.5783, Training Accuracy= 0.000\n",
      "Step 550, Minibatch Loss= 1.1911, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.6114, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.5830, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.5304, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.6799, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.5602, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.8257, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 1.0851, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.3295, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 1.3164, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 550, Minibatch Loss= 1.1523, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 0.8298, Training Accuracy= 1.000\n",
      "Step 550, Minibatch Loss= 2.3337, Training Accuracy= 0.000\n",
      "Step 560, Minibatch Loss= 0.5251, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.8168, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.3240, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.9494, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.2055, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.5259, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.4149, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.6625, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.8178, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 1.0763, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 0.3236, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 1.3082, Training Accuracy= 0.000\n",
      "Step 560, Minibatch Loss= 1.5715, Training Accuracy= 0.000\n",
      "Step 560, Minibatch Loss= 0.8218, Training Accuracy= 1.000\n",
      "Step 560, Minibatch Loss= 2.3221, Training Accuracy= 0.000\n",
      "Step 570, Minibatch Loss= 0.5207, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.8088, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.3181, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.5963, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.2027, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.5216, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 1.0575, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.3058, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.8095, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 1.0677, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.3178, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 2.2391, Training Accuracy= 0.000\n",
      "Step 570, Minibatch Loss= 1.1332, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 0.8137, Training Accuracy= 1.000\n",
      "Step 570, Minibatch Loss= 1.1288, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.5165, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.8011, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.3124, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.5892, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.1999, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.5173, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.4057, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.3135, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.8020, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 1.0596, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.3121, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 1.2911, Training Accuracy= 0.000\n",
      "Step 580, Minibatch Loss= 1.1273, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 0.8002, Training Accuracy= 1.000\n",
      "Step 580, Minibatch Loss= 2.3008, Training Accuracy= 0.000\n",
      "Step 590, Minibatch Loss= 0.5122, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 1.5485, Training Accuracy= 0.000\n",
      "Step 590, Minibatch Loss= 0.6395, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.5821, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.5597, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.5131, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.4012, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.2951, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.7923, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 1.0503, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.5416, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 1.2827, Training Accuracy= 0.000\n",
      "Step 590, Minibatch Loss= 1.1192, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 0.7979, Training Accuracy= 1.000\n",
      "Step 590, Minibatch Loss= 2.2899, Training Accuracy= 0.000\n",
      "Step 600, Minibatch Loss= 0.5080, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.7856, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.3014, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.5749, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.1945, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.5088, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.3960, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.6260, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.7862, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 1.0428, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.3011, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 1.2743, Training Accuracy= 0.000\n",
      "Step 600, Minibatch Loss= 1.1109, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 0.7901, Training Accuracy= 1.000\n",
      "Step 600, Minibatch Loss= 2.2786, Training Accuracy= 0.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.0\n",
      "Testing Accuracy: 1.0\n",
      "Testing Accuracy: 0.0\n",
      "Testing Accuracy: 0.0\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        for i in range(len(midi_note)-5):\n",
    "            batch_x = midi_note[i]\n",
    "            batch_y = midi_label[i]\n",
    "            # Reshape data to get 60*fs seq of 128 elements\n",
    "            batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for test\n",
    "    for i in range(5):\n",
    "        i = i+15\n",
    "        test_data = midi_note[i]\n",
    "        test_label = midi_label[i]\n",
    "        # Reshape data to get 60*fs seq of 128 elements\n",
    "        test_data = test_data.reshape((batch_size, timesteps, num_input))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
